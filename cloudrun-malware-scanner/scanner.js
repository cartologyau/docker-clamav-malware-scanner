/*
* Copyright 2024 Google LLC

* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at

*     https://www.apache.org/licenses/LICENSE-2.0

* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

const {logger} = require('./logger.js');

/** @typedef {import('./config.js').Config} Config */
/** @typedef {import('./config.js').BucketDefs} BucketDefs */
/** @typedef {import('node:stream').Readable} Readable */
/** @typedef {typeof import('./metrics.js')} MetricsClient */
/** @typedef {import('@google-cloud/storage').Storage} Storage */

// @ts-ignore -- TS7016: Could not find a declaration file
/** @typedef {typeof import('clamdjs')} ClamdClient */

const CLAMD_HOST = '127.0.0.1';
const CLAMD_PORT = 3310;

// 10 min timeout for scanning.
const CLAMD_TIMEOUT = 600000;

// Note: MAX_FILE_SIZE limits the size of files which are sent to th
// ClamAV Daemon.
//
// ClamAV itself has internal limits, which apply both to the total file
// size, and to the size of compressed files inside file containers.
// These are set in the clamd.conf file by bootstrap.sh
//
// Note scanning a 500MiB file can take 5 minutes, so ensure timeout is
// large enough.
const MAX_FILE_SIZE = 500000000; // 500MiB

/**
 * StorageObjectData object defined at:
 *  https://github.com/googleapis/google-cloudevents/blob/main/proto/google/events/cloud/storage/v1/data.proto
 *
 * @typedef {{
 *  name: string,
 *  bucket: string,
 *  size: string | number
 * }} StorageObjectData
 *
 * @typedef {{
 *  status: string,
 *  message: string,
 *  clam_version?: string
 * }} ScanResponse
 */

/**
 * the clamd scanner.scanStream function signature.
 * @typedef {(stream: Readable, timeout: number) => Promise<string> } ScanStreamFunc
 */

/**
 * Class to encapsulate the interface with ClamD and the scanning process.
 */
class Scanner {
  /**
   * @param {Config} config
   * @param {ClamdClient} clamdClient
   * @param {Storage} storageClient
   * @param {MetricsClient} metricsClient
   */
  constructor(config, clamdClient, storageClient, metricsClient) {
    this.config = config;
    this.clamdClient = clamdClient;
    this.storageClient = storageClient;
    this.metricsClient = metricsClient;

    this.clamdScanStream = /** @type {ScanStreamFunc} */ (
      /** @type {any} */ (clamdClient.createScanner(CLAMD_HOST, CLAMD_PORT))
        .scanStream
    );
  }

  /**
   * Wrapper to get a clean string with the version of CLAM.
   * @return {Promise<string>}
   */
  async getClamVersion() {
    return (await this.clamdClient.version(CLAMD_HOST, CLAMD_PORT)).replace(
      '\x00',
      '',
    );
  }

  /** Wrapper to return on ping success or throw. */
  async pingClamD() {
    if (!(await this.clamdClient.ping(CLAMD_HOST, CLAMD_PORT))) {
      // ping can return false, or throw...
      throw new Error('clamd PING failed');
    }
  }

  /** @param {StorageObjectData} storageObject  */
  validateStorageObject(storageObject) {
    if (storageObject == null) {
      throw new Error('No storage object in request');
    }
    if (storageObject?.name == null) {
      throw new Error('file name not specified in request');
    }
    if (storageObject?.bucket == null) {
      throw new Error('bucket name not specified in request');
    }
    // file.size can be 0, which is falsey and == null, so check with ===
    if (storageObject?.size === null || storageObject?.size === undefined) {
      throw new Error('object size not specified in request');
    }
  }

  /**
   * Handle a POST with a GCS object payload.
   *
   * @param {StorageObjectData} storageObject cloud storage object data.
   * @returns {Promise<ScanResponse>}
   */
  async handleGcsObject(storageObject) {
    try {
      let bucketDefs;

      try {
        this.validateStorageObject(storageObject);
        bucketDefs = this.config.buckets.filter(
          (bucketDefs) => bucketDefs.unscanned === storageObject.bucket,
        )[0];
        if (bucketDefs == null) {
          throw new Error(
            'Request has bucket name ${storageObject.bucket} which is not an unscanned bucket in config',
          );
        }
      } catch (e) {
        logger.error(`Ignoring request: ${e}`);
        this.metricsClient.writeScanFailed();
        return {message: 'ignoring invalid request', status: 'ignored'};
      }

      // Check for zero length file:
      const fileSize = parseInt(String(storageObject.size));
      if (fileSize === 0 && this.config.ignoreZeroLengthFiles) {
        logger.info(
          `Scan status for gs://${storageObject.bucket}/${storageObject.name}: IGNORED (zero length file})`,
        );
        this.metricsClient.writeScanIgnored(
          bucketDefs.unscanned,
          bucketDefs.clean,
          fileSize,
          'ZERO_LENGTH_FILE',
        );
        return {status: 'ignored', message: 'zero_length_file'};
      }

      // Check if the file is too big to process
      if (fileSize > MAX_FILE_SIZE) {
        logger.info(
          `Scan status for gs://${storageObject.bucket}/${storageObject.name}: IGNORED (file too large at ${fileSize} bytes})`,
        );
        this.metricsClient.writeScanIgnored(
          bucketDefs.unscanned,
          bucketDefs.clean,
          fileSize,
          'FILE_TOO_LARGE',
        );
        return {status: 'ignored', message: 'file_too_large'};
      }

      // Check if filename is excluded:
      // Iterate through the configured file exclusion patterns.
      // If the file name matches any of the exclusion patterns, log an informational message and return an "ignored" status to the client.
      // This allows specific files to be skipped from the scanning process based on their names.
      for (const regexp of this.config.fileExclusionRegexps) {
        if (regexp.test(storageObject.name)) {
          logger.info(
            `Scan status for gs://${storageObject.bucket}/${storageObject.name}: IGNORED (matched regex: ${regexp.toString()})`,
          );
          this.metricsClient.writeScanIgnored(
            bucketDefs.unscanned,
            bucketDefs.clean,
            fileSize,
            'REGEXP_MATCH',
            regexp.toString(),
          );
          return {status: 'ignored', message: 'exclusion_regexp_match'};
        }
      }

      // Validate file exists
      const gcsFile = this.storageClient
        .bucket(storageObject.bucket)
        .file(storageObject.name);

      // File.exists() returns a FileExistsResponse, which is a list with a
      // single value.
      if (!(await gcsFile.exists())[0]) {
        // Warn in logs, but return successful to client.
        logger.warn(
          `Ignoring no longer existing file: gs://${gcsFile.bucket}/${gcsFile.name}`,
        );
        return {status: 'ignored', message: 'file deleted'};
      }

      // Compare file size from the request body ('file.size') to the file metadata ('metadata.size').
      // If the sizes don't match, log an informational message indicating a potential incomplete file upload and return a "ignored" status to the client.
      // This check helps avoid scanning partially uploaded files, which might lead to inaccurate scan results.
      const [metadata] = await gcsFile.getMetadata();
      const metadataSize = parseInt(String(metadata.size));
      if (fileSize !== metadataSize) {
        logger.info(
          `Scan status for gs://${gcsFile.bucket}/${gcsFile.name}: IGNORED (File size mismatch (reported: ${fileSize}, metadata: ${metadataSize}). File upload may not be complete).`,
        );
        this.metricsClient.writeScanIgnored(
          bucketDefs.unscanned,
          bucketDefs.clean,
          fileSize,
          'FILE_SIZE_MISMATCH',
        );
        return {status: 'ignored', message: 'file_size_mismatch'};
      }

      const clamdVersion = await this.getClamVersion();
      logger.info(
        `Scan request for gs://${gcsFile.bucket}/${gcsFile.name}, (${fileSize} bytes) scanning with clam ${clamdVersion}`,
      );
      const startTime = Date.now();
      const readStream = await gcsFile.createReadStream();
      let result;
      try {
        result = await this.clamdScanStream(readStream, CLAMD_TIMEOUT);
      } finally {
        // Ensure stream is destroyed in all situations to prevent any
        // resource leaks.
        readStream.destroy();
      }
      const scanDuration = Date.now() - startTime;

      if (this.clamdClient.isCleanReply(result)) {
        logger.info(
          `Scan status for gs://${gcsFile.bucket}/${gcsFile.name}: CLEAN (${fileSize} bytes in ${scanDuration} ms)`,
        );
        this.metricsClient.writeScanClean(
          bucketDefs.unscanned,
          bucketDefs.clean,
          fileSize,
          scanDuration,
          clamdVersion,
        );

        // Move document to the bucket that holds clean documents. This can
        // fail due to permissions or if the file has been deleted.
        await this.moveProcessedFile(gcsFile.name, true, bucketDefs);

        // Respond to API client.
        return {
          status: 'clean',
          clam_version: clamdVersion,
          message: 'scan_success',
        };
      } else {
        logger.warn(
          `Scan status for gs://${gcsFile.bucket}/${gcsFile.name}: INFECTED ${result} (${fileSize} bytes in ${scanDuration} ms)`,
        );
        this.metricsClient.writeScanInfected(
          bucketDefs.unscanned,
          bucketDefs.quarantined,
          fileSize,
          scanDuration,
          clamdVersion,
        );

        // Move document to the bucket that holds infected documents. This can
        // fail due to permissions or if the file has been deleted.
        await this.moveProcessedFile(gcsFile.name, false, bucketDefs);

        // Respond to API client.
        return {
          message: result,
          status: 'infected',
          clam_version: clamdVersion,
        };
      }
    } catch (e) {
      logger.error(
        {err: e},
        `Exception when processing gs://${storageObject.bucket}/${storageObject.name}: ${e}`,
      );

      // Check for an API error code
      const errcode = /** @type {import('@google-cloud/storage').ApiError} */ (
        e
      ).code;
      if (errcode && [403, 404].includes(errcode)) {
        // Permission denied/file not found can be raised by the stream reading
        // and by the object move. They cannot be retried, so respond
        // with success, but log the error.
        return {status: 'error', message: 'Error when reading file, ignoring'};
      }
      this.metricsClient.writeScanFailed(storageObject.bucket);
      throw e;
    }
  }

  /**
   * Move the file to the appropriate bucket.
   * @async
   * @param {string} filename
   * @param {boolean} isClean
   * @param {!import('./config.js').BucketDefs} config
   */
  async moveProcessedFile(filename, isClean, config) {
    const srcBucketName = config.unscanned;
    const srcfile = this.storageClient.bucket(srcBucketName).file(filename);
    const destinationBucketName = isClean ? config.clean : config.quarantined;
    const destinationBucket = this.storageClient.bucket(destinationBucketName);

    await srcfile.move(destinationBucket);
    logger.info(
      `Successfully moved file gs://${srcBucketName}/${filename} to gs://${destinationBucketName}/${filename}`,
    );
  }
}

module.exports = {
  Scanner,
};
